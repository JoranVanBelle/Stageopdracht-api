# server:
#   port: 5000

#springdoc:
#   api-docs:
#      path: /api-docs
#   swagger-ui:
#      path: /swagger-api-docs.html
#      supportedSubmitMethods: ["get"]

spring:
#   application:
#      name: API
   datasource:
      url: jdbc:postgresql:///${DATABASE_NAME}?cloudSqlInstance=${DATABASE_INSTANCE_CONNECTION_NAME}&socketFactory=com.google.cloud.sql.postgres.SocketFactory&user=${DATABASE_USERNAME}&password=${DATABASE_PASSWORD}
      username: ${DATABASE_USERNAME}
      password: ${DATABASE_PASSWORD}
#   task:
#      executor:
#         keep-alive: 9223372036854775807s

   kafka:
      topicFeedback: Kiten.Feedback
      topicSubscription: Kiten.subscription
      bootstrap-servers: ${BOOTSTRAP_SERVERS}
      
      properties:
         sasl.mechanism: PLAIN
         bootstrap.servers: ${BOOTSTRAP_SERVERS}
         sasl.jaas.config: "org.apache.kafka.common.security.plain.PlainLoginModule required username='${CLUSTER_API_KEY}' password='${CLUSTER_API_SECRET}';"
         security.protocol: SASL_SSL
         session.timeout.ms: 45000
         basic.auth:
            credentials.source: USER_INFO
            user.info: ${SR_API_KEY}:${SR_API_SECRET}
         
         schema.registry.url: ${SCHEMA_REGISTRY_URL}      
    
      consumer:
         keyDeserializer: org.apache.kafka.common.serialization.StringDeserializer
         valueDeserializer: io.confluent.kafka.serializers.KafkaAvroDeserializer
         specificAvroReaderConfig: true
         
         groupId: adapter_mvb
         autoOffsetReset: earliest
         enableAutoCommit: true
      
      producer:
         keySerializer: org.apache.kafka.common.serialization.StringSerializer
         valueSerializer: io.confluent.kafka.serializers.KafkaAvroSerializer
         value.subject.name.strategy: io.confluent.kafka.serializers.subject.TopicRecordNameStrategy
         
         acks: all
         retries: 0

email:
   host: ${EMAIL_HOST}
   port: ${EMAIL_PORT}
   username: ${EMAIL_USERNAME}
   password: ${EMAIL_PASSWORD}